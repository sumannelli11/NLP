{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b1fef2",
   "metadata": {},
   "source": [
    "To illustrate how the Bag of Words (BOW) model can be used for spam detection with a Naive Bayes classifier, let's walk through a simplified example.\n",
    "\n",
    "### Step 1: Collect Sample Emails\n",
    "Let's say we have a small dataset of emails labeled as \"spam\" or \"not spam\" (ham).\n",
    "\n",
    "**Spam emails:**\n",
    "1. \"Buy cheap watches now\"\n",
    "2. \"Win money in our lottery\"\n",
    "3. \"Cheap meds available\"\n",
    "\n",
    "**Not spam emails (Ham):**\n",
    "1. \"Meeting scheduled at noon\"\n",
    "2. \"Lunch plans for tomorrow\"\n",
    "3. \"Project deadline extended\"\n",
    "\n",
    "### Step 2: Create Vocabulary\n",
    "From these emails, we create a vocabulary of unique words:\n",
    "```\n",
    "[\"buy\", \"cheap\", \"watches\", \"now\", \"win\", \"money\", \"in\", \"our\", \"lottery\", \"meds\", \"available\", \"meeting\", \"scheduled\", \"at\", \"noon\", \"lunch\", \"plans\", \"for\", \"tomorrow\", \"project\", \"deadline\", \"extended\"]\n",
    "```\n",
    "\n",
    "### Step 3: Create the Bag of Words Model\n",
    "Transform each email into a vector based on the frequency of words in the vocabulary.\n",
    "\n",
    "**Spam email vectors:**\n",
    "1. \"Buy cheap watches now\" → [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "2. \"Win money in our lottery\" → [0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "3. \"Cheap meds available\" → [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "**Ham email vectors:**\n",
    "1. \"Meeting scheduled at noon\" → [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "2. \"Lunch plans for tomorrow\" → [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0]\n",
    "3. \"Project deadline extended\" → [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
    "\n",
    "### Step 4: Train the Naive Bayes Classifier\n",
    "Using the vectors above, we train the Naive Bayes classifier. During training, the classifier calculates the probability of each word given each class (spam or ham).\n",
    "\n",
    "### Step 5: Classify New Emails\n",
    "Let's say we have a new email to classify: \"Cheap lottery win\".\n",
    "\n",
    "Convert it into a BOW vector:\n",
    "```\n",
    "\"Cheap lottery win\" → [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "```\n",
    "\n",
    "### Step 6: Apply Naive Bayes Classification\n",
    "Using the learned probabilities, we calculate the likelihood that the email is spam versus ham.\n",
    "\n",
    "For example, assume the trained probabilities are:\n",
    "- P(Spam) = 0.5, P(Ham) = 0.5 (equal probability)\n",
    "- P(Cheap|Spam) = 0.33, P(Cheap|Ham) = 0.1\n",
    "- P(Lottery|Spam) = 0.33, P(Lottery|Ham) = 0.05\n",
    "- P(Win|Spam) = 0.33, P(Win|Ham) = 0.05\n",
    "\n",
    "Using Naive Bayes formula:\n",
    "```\n",
    "P(Spam|Email) ∝ P(Spam) * P(Cheap|Spam) * P(Lottery|Spam) * P(Win|Spam)\n",
    "              ∝ 0.5 * 0.33 * 0.33 * 0.33\n",
    "\n",
    "P(Ham|Email) ∝ P(Ham) * P(Cheap|Ham) * P(Lottery|Ham) * P(Win|Ham)\n",
    "             ∝ 0.5 * 0.1 * 0.05 * 0.05\n",
    "```\n",
    "\n",
    "Calculate the final probabilities (normalized):\n",
    "```\n",
    "P(Spam|Email) ∝ 0.5 * 0.33 * 0.33 * 0.33 ≈ 0.018\n",
    "P(Ham|Email) ∝ 0.5 * 0.1 * 0.05 * 0.05 ≈ 0.000125\n",
    "```\n",
    "\n",
    "Since P(Spam|Email) > P(Ham|Email), the email is classified as spam.\n",
    "\n",
    "### Conclusion\n",
    "This example demonstrates how the Bag of Words model can be applied to transform text data into a numerical format suitable for Naive Bayes classification, which then helps in identifying spam emails based on word frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd41861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
